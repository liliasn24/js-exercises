<h1>Split()</h1>
<p>The split method divides a string into an ordered list of substrings, puts these substrings into an array, and returns the array. The division is done by searching for a pattern; wher the pattern is provided as the first parameter in the method's call.
    split()
    split(separator)
    split(separator, limit)
</p>

<h1>Splice()</h1>
<p>The splice() method changes the contents of an array by removing or replacing existing elements and/or adding new elements in place.

splice(start)
splice(start, deleteCount)
splice(start, deleteCount, item1)
splice(start, deleteCount, item1, item2, itemN)
</p>

<h1>Slice</h1>
<p>The slice() method returns a shallow copy of a portion of an array into a new array object selected from start to end (end not included) where start and end represent the index of items in that array. The original array will not be modified.

    slice();
    slice(start);
    slice(start, end);
</p>

<h1>Spread syntax</h1>
<p>Spread syntax can be used when all elements from an object or array need to be included in a list of some kind.</p>

<p>What is CS?
    Problem solving, including engeneering, computer, tech. How computers works, the theory behind or the study of problems, standardized solutions to those problems and how to make those solutions more efficient
</p>

<p>What is an Algorithm?
    Simply put, an algorithm is a process. A set of instructions that tells a computer how to solve a problem.
    Sort and Search algorithms.
    Sorts organizes data, search finds a specific thing.
    Time: The maximum amount of time it would take the algorithm to solve a problem.
    Space: The maximum amount of computer memory, or RAM, the algorithm needs to run.
</p>

<p>Big O Notation
    Algorithm complexity. Time and Space efficency. By knowing the complexity of the data we can select the best apporach.

    Interviewers want to make sure that you understand the difference between efficiency and inefficiency so that you aren’t writing code that takes excessive memory or energy to run.

You could be asked to look at an algorithm, determine its Big O complexity, and give your reasoning. If so, keep the following considerations in mind:

Does the function have to go through an entire list? If so, there’s an N in that Big O class somewhere.
Are there nested loops? That might give you O(N^2) (or worse).
Does the function break the list into smaller chunks? You could have O(log(N)).
Is the amount of work the same, regardless of the size of the data set? You might have O(1).
You could also be asked to describe how a given function could be rewritten more efficiently. As you’ve probably realized, most functions can be written in multiple ways. Big O helps you understand the most efficient way to write functions.
0(1) - this is the most efficient.
0(N)
0(log(N))
0(N>2) - quandratic complexity, the least efficient

</p>

<h1>Recursion</h1>

<p>In a nut shell recursion is when a function calls itself, like a loop, it helps you break down a problem in smaller parts.

We can break down the process of a recursive function into three steps:

Base case: When the process can stop.
Action: Put that function to work!
Recursive case: The function is called again but with the assurance that progress is being made toward the base case.
</p>

<h1>HTTP STATUS CODES</h1>
<p>
200 Success
201 created204 No content
100 Informational
400 Client Error/bad request
401 Unauthorized
404 Not found

500 Server error/internal server error

The Best Case

An algorithm’s best-case performance is called its “Big Omega,” or Ω (that’s the Greek symbol for Omega). Big Omega describes how fast an algorithm would run if it performed the fewest possible actions on a data set. If you were sorting an already sorted set, you’d get the Big Omega value.

The Average Case

An algorithm’s average-case performance is called its “Big Theta,” or Θ (another Greek symbol). Big Theta describes the typical runtime of an algorithm.

Stability (whether or not the items in the set stay in order).
Sorting method (comparison, distribution, or a combination of the two).
The size and structure of your data (sorted, unsorted, very large, etc.).
</p>

<h1>Bubble and Insertion algorithm</h1>
<p>For bubble sort: Start at the beginning of an array of items.
    Compare the item you’re looking at to the next item in the list.
    If this item is smaller than the next one, keep it in place. If it’s greater, swap them.
    Move on to the next item.
    Repeat Steps 1–4 until you can go through the whole list without making any swaps.

    For insertion sort: each card you take moves to the place it goes comparing it the the previous card.
    https://www.youtube.com/watch?v=ROalU379l3U this video is hilarious 

</p>

<h1>HTTP Requests</h1>
<p>GET, POST, PUT/PATCH, DELETE</p>

<h1>Distribution sort</h1>
<p>bucket sort and radix sort
Bucket sort is a lot like the essay-grading scenario we just explored. It sorts elements into buckets based on their value and then uses another method to sort the elements within those bins. It can be used for integers or strings.
Radix sort operates in basically the same way as bucket sort but is only used for integers.
</p>

<h1>Reverse method</h1>
<p>The reverse() method reverses an array in place. The first element becomes the last and the last array elemetn becomes the first </p>

<h1>Join method</h1>
<p>The join() method creates and return a new string by concatenating all the elements in an array (or an array-like object), separated by comas or a specified separator string.</p>

<h1>Merge sort and quick sort</h1>
<p>These methods use a type of recursion.</p>

<h1>Merge sort continued</h1>
<p>Merge sort consists of 2 algorithms, the firs is merge sort an the second one is  merge. The 1st one splits the array in half over and over, the second one merges those pieces back together. The recursion is used on the merge sort part (it divides until it gets to the base case) </p>